{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmat6HkMzR5Y",
        "outputId": "ab7213f6-5798-44de-a33f-c0ba96b0e4ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (2.0.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (2.9.0+cpu)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.3)\n",
            "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytorch-tabnet\n",
            "Successfully installed pytorch-tabnet-4.1.0\n",
            "‚è≥ Loading Real Dataset...\n",
            "üßπ Cleaning Data...\n",
            "üõ†Ô∏è Engineering Features...\n",
            "\n",
            "üöÄ Training Model (This may take 1-2 mins)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.86969 | train_auc: 0.5535  | train_accuracy: 0.56125 | valid_auc: 0.70588 | valid_accuracy: 0.60714 |  0:00:00s\n",
            "epoch 1  | loss: 0.47844 | train_auc: 0.62072 | train_accuracy: 0.87305 | valid_auc: 0.41961 | valid_accuracy: 0.875   |  0:00:00s\n",
            "epoch 2  | loss: 0.35186 | train_auc: 0.4357  | train_accuracy: 0.90423 | valid_auc: 0.43529 | valid_accuracy: 0.91071 |  0:00:00s\n",
            "epoch 3  | loss: 0.30767 | train_auc: 0.47036 | train_accuracy: 0.90646 | valid_auc: 0.3451  | valid_accuracy: 0.91071 |  0:00:00s\n",
            "epoch 4  | loss: 0.27835 | train_auc: 0.48339 | train_accuracy: 0.90646 | valid_auc: 0.34902 | valid_accuracy: 0.91071 |  0:00:00s\n",
            "epoch 5  | loss: 0.27772 | train_auc: 0.46128 | train_accuracy: 0.90646 | valid_auc: 0.36471 | valid_accuracy: 0.91071 |  0:00:00s\n",
            "epoch 6  | loss: 0.28591 | train_auc: 0.45326 | train_accuracy: 0.90646 | valid_auc: 0.38039 | valid_accuracy: 0.91071 |  0:00:00s\n",
            "epoch 7  | loss: 0.27481 | train_auc: 0.44166 | train_accuracy: 0.90646 | valid_auc: 0.38824 | valid_accuracy: 0.91071 |  0:00:00s\n",
            "epoch 8  | loss: 0.25295 | train_auc: 0.46159 | train_accuracy: 0.89755 | valid_auc: 0.41176 | valid_accuracy: 0.91071 |  0:00:00s\n",
            "epoch 9  | loss: 0.27281 | train_auc: 0.47331 | train_accuracy: 0.90423 | valid_auc: 0.45882 | valid_accuracy: 0.91071 |  0:00:00s\n",
            "epoch 10 | loss: 0.25026 | train_auc: 0.499   | train_accuracy: 0.89978 | valid_auc: 0.46275 | valid_accuracy: 0.91071 |  0:00:00s\n",
            "epoch 11 | loss: 0.24645 | train_auc: 0.50255 | train_accuracy: 0.90646 | valid_auc: 0.45882 | valid_accuracy: 0.91071 |  0:00:01s\n",
            "epoch 12 | loss: 0.24886 | train_auc: 0.47437 | train_accuracy: 0.90646 | valid_auc: 0.47059 | valid_accuracy: 0.91071 |  0:00:01s\n",
            "epoch 13 | loss: 0.24537 | train_auc: 0.4384  | train_accuracy: 0.90646 | valid_auc: 0.40784 | valid_accuracy: 0.91071 |  0:00:01s\n",
            "epoch 14 | loss: 0.2438  | train_auc: 0.41935 | train_accuracy: 0.89755 | valid_auc: 0.43529 | valid_accuracy: 0.875   |  0:00:01s\n",
            "epoch 15 | loss: 0.25099 | train_auc: 0.42591 | train_accuracy: 0.89532 | valid_auc: 0.44706 | valid_accuracy: 0.875   |  0:00:01s\n",
            "epoch 16 | loss: 0.23869 | train_auc: 0.41451 | train_accuracy: 0.89978 | valid_auc: 0.4     | valid_accuracy: 0.875   |  0:00:01s\n",
            "epoch 17 | loss: 0.23455 | train_auc: 0.4223  | train_accuracy: 0.89978 | valid_auc: 0.38039 | valid_accuracy: 0.875   |  0:00:01s\n",
            "\n",
            "Early stopping occurred at epoch 17 with best_epoch = 2 and best_valid_accuracy = 0.91071\n",
            "\n",
            "üèÜ FINAL ACCURACY: 89.47%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Clean       0.89      1.00      0.94        51\n",
            " Defect Risk       0.00      0.00      0.00         6\n",
            "\n",
            "    accuracy                           0.89        57\n",
            "   macro avg       0.45      0.50      0.47        57\n",
            "weighted avg       0.80      0.89      0.85        57\n",
            "\n",
            "Successfully saved model at tabnet_quality_model.zip\n",
            "\n",
            "‚úÖ SUCCESS! Download these 2 files from the files panel:\n",
            "1. tabnet_quality_model.zip\n",
            "2. le_prio_quality.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# üìö QUALITY RISK MODEL TRAINER (REAL DATA OPTIMIZED)\n",
        "# =============================================================================\n",
        "# This script cleans your CSV, engineers the exact 6 features your backend needs,\n",
        "# and trains a TabNet model with Class Balancing to ensure >60% accuracy.\n",
        "# =============================================================================\n",
        "\n",
        "# 1. INSTALL\n",
        "!pip install pytorch-tabnet pandas scikit-learn joblib matplotlib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import joblib\n",
        "\n",
        "# ==========================================\n",
        "# 2. LOAD & CLEAN DATA\n",
        "# ==========================================\n",
        "print(\"‚è≥ Loading Real Dataset...\")\n",
        "try:\n",
        "    df_raw = pd.read_csv('agile_event_stream_dataset_6k.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå ERROR: Please upload 'agile_event_stream_dataset_6k.csv' to the notebook files!\")\n",
        "    raise\n",
        "\n",
        "# CLEANING: The snippet showed -1.0 for missing values. We fix that.\n",
        "print(\"üßπ Cleaning Data...\")\n",
        "cols_to_clean = ['Story_Point', 'total_links', 'total_comments']\n",
        "for col in cols_to_clean:\n",
        "    df_raw[col] = df_raw[col].replace(-1.0, 0).fillna(0)\n",
        "\n",
        "# ==========================================\n",
        "# 3. FEATURE ENGINEERING (MATCHING BACKEND)\n",
        "# ==========================================\n",
        "print(\"üõ†Ô∏è Engineering Features...\")\n",
        "\n",
        "# A. Author Workload (14-Day Rolling Count)\n",
        "# We need to turn the 'Creation_Date_Change' into a workload metric\n",
        "df_raw['date'] = pd.to_datetime(df_raw['Creation_Date_Change'], errors='coerce')\n",
        "df_raw = df_raw.sort_values(['Author_ID', 'date'])\n",
        "\n",
        "# Calculate active tickets in last 14 days per author\n",
        "# (Using a simple rolling count approximate for speed)\n",
        "df_raw['active_tickets_14d'] = df_raw.groupby('Author_ID')['date'].transform(\n",
        "    lambda x: x.diff().dt.days.fillna(0).rolling(window=5, min_periods=1).sum().apply(lambda d: 14 - d if d < 14 else 0)\n",
        ")\n",
        "# Normalizing workload to be a count-like integer (0-15 range)\n",
        "df_raw['active_tickets_14d'] = df_raw['active_tickets_14d'].clip(lower=0).fillna(0).astype(int)\n",
        "\n",
        "# B. Aggregate to Issue Level (We only want one row per ticket)\n",
        "# We take the MAX values for points/links to capture the final state\n",
        "df = df_raw.groupby('Issue_ID').agg({\n",
        "    'Story_Point': 'max',\n",
        "    'total_links': 'max',\n",
        "    'total_comments': 'max',\n",
        "    'active_tickets_14d': 'mean', # Avg workload during ticket life\n",
        "    'Priority': 'first',\n",
        "    'Type': 'first'\n",
        "}).reset_index()\n",
        "\n",
        "# C. Complexity Interaction (Feature #5)\n",
        "df['complexity_interaction'] = df['Story_Point'] * (df['total_links'] + 1)\n",
        "\n",
        "# D. Priority Code (Feature #6)\n",
        "le_prio = LabelEncoder()\n",
        "# Ensure all standard priorities exist in encoder even if missing in data\n",
        "standard_prios = ['Highest', 'High', 'Medium', 'Low', 'Lowest']\n",
        "le_prio.fit(standard_prios)\n",
        "# Map data, defaulting to 'Medium' (index 2) if unknown\n",
        "df['Priority_Code'] = df['Priority'].apply(lambda x: le_prio.transform([x])[0] if x in standard_prios else 2)\n",
        "\n",
        "# ==========================================\n",
        "# 4. PREPARE TRAINING DATA\n",
        "# ==========================================\n",
        "# Target: 1 if Bug, 0 if Story/Task\n",
        "df['is_defect'] = df['Type'].apply(lambda x: 1 if x == 'Bug' else 0)\n",
        "\n",
        "# EXACT 6 FEATURES REQUIRED BY MAIN.PY\n",
        "features = [\n",
        "    'Story_Point',            # 1\n",
        "    'total_links',            # 2\n",
        "    'total_comments',         # 3\n",
        "    'active_tickets_14d',     # 4\n",
        "    'complexity_interaction', # 5\n",
        "    'Priority_Code'           # 6\n",
        "]\n",
        "\n",
        "X = df[features].values\n",
        "y = df['is_defect'].values\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)\n",
        "\n",
        "# ==========================================\n",
        "# 5. TRAIN TABNET (WITH CLASS WEIGHTS)\n",
        "# ==========================================\n",
        "print(\"\\nüöÄ Training Model (This may take 1-2 mins)...\")\n",
        "\n",
        "# Calculate weights to fix \"Class Imbalance\" (Too few bugs vs stories)\n",
        "# This forces the model to learn about bugs, improving accuracy beyond 60%\n",
        "cls_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "# TabNet doesn't take class_weight directly in init, so we pass it custom or use a trick\n",
        "# We will use the 'weights' parameter in fit() which effectively oversamples\n",
        "sample_weights = np.array([cls_weights[val] for val in y_train])\n",
        "\n",
        "clf = TabNetClassifier(\n",
        "    n_d=8, n_a=8, n_steps=3,    # Smaller architecture prevents overfitting on 6k rows\n",
        "    gamma=1.3,\n",
        "    lambda_sparse=1e-3,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    mask_type='entmax',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "clf.fit(\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "    eval_name=['train', 'valid'],\n",
        "    eval_metric=['auc', 'accuracy'],\n",
        "    max_epochs=100,\n",
        "    patience=15,\n",
        "    batch_size=256,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 6. EVALUATE & SAVE\n",
        "# ==========================================\n",
        "preds = clf.predict(X_test)\n",
        "acc = accuracy_score(y_test, preds)\n",
        "print(f\"\\nüèÜ FINAL ACCURACY: {acc*100:.2f}%\")\n",
        "print(classification_report(y_test, preds, target_names=['Clean', 'Defect Risk']))\n",
        "\n",
        "# SAVE\n",
        "clf.save_model(\"tabnet_quality_model\")\n",
        "joblib.dump(le_prio, \"le_prio_quality.pkl\")\n",
        "\n",
        "print(\"\\n‚úÖ SUCCESS! Download these 2 files from the files panel:\")\n",
        "print(\"1. tabnet_quality_model.zip\")\n",
        "print(\"2. le_prio_quality.pkl\")"
      ]
    }
  ]
}